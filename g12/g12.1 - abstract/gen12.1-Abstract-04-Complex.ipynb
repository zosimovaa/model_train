{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "## Task #1\n",
    "\n",
    "**Цель**\n",
    "Обучаем сеть корректной последовательности действий на бирже: ожидание покупки -> покупка -> ожидание продажи -> продажа.\n",
    " \n",
    "**Observation**\n",
    " - Состояние сделки\n",
    "\n",
    "**Действия**\n",
    " 1. Ожидание момента для покупки\n",
    " 2. Покупка (открытие позиции)\n",
    " 3. Ожидание момента для продажи\n",
    " 4. Продажа (закрытие позици)\n",
    "\n",
    "**Награда/штраф**\n",
    "Действия 1 и 2 возможны при отсутствии открытой позиции. Действия 3 и 4 допустимы только при открытой позиции. При нарушении этого требования - сеть штрафуется.\n",
    " \n",
    "Сеть получает награду при закрытии позиции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen12.1-Abstract-04-Complex\n"
     ]
    }
   ],
   "source": [
    "# Системные импорты и настройки\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import random\n",
    "import warnings\n",
    "import ipynbname\n",
    "import logging.config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for local development\n",
    "RT_LIBS_PATH = \"/Users/alex/Dev_projects/MyOwnRepo/rt_libs/src\"\n",
    "BA_LIBS_PATH = \"/Users/alex/Dev_projects/MyOwnRepo/basic_application/src\"\n",
    "sys.path.append(RT_LIBS_PATH)\n",
    "sys.path.append(BA_LIBS_PATH)\n",
    "\n",
    "# read config\n",
    "with open('config.yaml', \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    \n",
    "# set logging config\n",
    "log_config = config.get(\"log\", None)\n",
    "logging.config.dictConfig(log_config)\n",
    "\n",
    "# set notebook alias\n",
    "ALIAS = ipynbname.name()\n",
    "print(ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS frameworks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 12:01:22.336471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# NN Frameworks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, AveragePooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import load_model, clone_model\n",
    "\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT packages\n",
    "from rl import DQNAgent\n",
    "from env import TradeEnv\n",
    "from core_v2 import Constructor, Player\n",
    "\n",
    "\n",
    "from core_v2.data_point import DataPointFactory\n",
    "\n",
    "from core_v2.observation_builder.precompute import PrecomputeOrderbookDiffFeature\n",
    "\n",
    "from train_tools import plot_and_go\n",
    "from train_tools.train_plot import TrainPlot4\n",
    "from train_tools.train_manager import TrainManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 0\n",
    "#os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "#np.random.seed(seed_value)\n",
    "#tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конфиг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_len = 1\n",
    "\n",
    "# Параметры точки наблюдения\n",
    "observation_config = {\n",
    "    \"observation_len\": observation_len,             # Количество точек наблюдения в сэмпле\n",
    "    \"offset\": observation_len,                      # Количество точек наблюдения в сэмпле\n",
    "    \"future_points\": 0,                             # Количество будущех точек для предсказания тренда (временное решение)\n",
    "    \"step_size\": 1,                                 # Шаг по датасету\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 1.  1.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.5 0.  1. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [0.5 1.  1.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.  0.  0. ]\n",
      " [1.  1.5 0.  1. ]\n",
      " [1.  1.  0.  0. ]]\n",
      "lowest_ask       95.0\n",
      "highest_bid     105.0\n",
      "open_signal      10.0\n",
      "close_signal     10.0\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "sample_num = 10\n",
    "sample_size = n_steps//sample_num\n",
    "\n",
    "shift_size = 8\n",
    "\n",
    "open_signal = np.empty(0)\n",
    "close_signal = np.empty(0)\n",
    "\n",
    "for i in range(sample_num):\n",
    "    sample_shift_size = np.random.randint(1, shift_size)\n",
    "    shift = np.zeros(sample_shift_size)\n",
    "    \n",
    "    sample_size_ = sample_size - sample_shift_size\n",
    "    \n",
    "    total = 2\n",
    "    \n",
    "    while not total==1:\n",
    "        sample = np.random.uniform(size=sample_size_) > 0.9\n",
    "        total = sum(sample)\n",
    "    \n",
    "    \n",
    "    open_signal = np.concatenate([open_signal, sample, shift])\n",
    "    close_signal = np.concatenate([close_signal, shift, sample])\n",
    "    \n",
    "    \n",
    "lowest_ask = np.ones(len(open_signal)) - open_signal*0.5\n",
    "highest_bid = np.ones(len(open_signal)) + close_signal*0.5\n",
    "\n",
    "    \n",
    "dataset = np.concatenate([\n",
    "    lowest_ask.reshape(-1,1), \n",
    "    highest_bid.reshape(-1,1), \n",
    "    open_signal.reshape(-1,1), \n",
    "    close_signal.reshape(-1,1)\n",
    "], axis=1)\n",
    "data_train = pd.DataFrame(dataset, columns=[\"lowest_ask\", \"highest_bid\", \"open_signal\", \"close_signal\"], dtype=np.float32)\n",
    "\n",
    "#data_train['open_signal']  = data_train['open_signal']  - 0.5\n",
    "#data_train['open_signal'] = data_train['open_signal'] * 2\n",
    "#data_train['close_signal']  = data_train['close_signal']  - 0.5\n",
    "#data_train['close_signal'] = data_train['close_signal'] * 2\n",
    "\n",
    "print(data_train.values[:20])\n",
    "print(data_train.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация компонентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapoint factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpf_train = DataPointFactory(dataset=data_train, **observation_config)\n",
    "dpf_test = DataPointFactory(dataset=data_train, **observation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_config = {\n",
    "    \"action_controller\":{\"class\": \"AbstractTrainControllerOpenCloseSignal\", \"params\":{ \n",
    "            \"penalty\": -1, \n",
    "            \"wait_scale\": 0, \n",
    "            \"open_scale\": 0, \n",
    "            \"hold_scale\": 0, \n",
    "            \"close_scale\": 1, \n",
    "            \"last_points_mean\": 0\n",
    "        },},\n",
    "\n",
    "\n",
    "    \"observation_builder\":{\n",
    "        \"class\": \"ObservationBuilder\",\n",
    "        \"inputs\": [\n",
    "            {\"class\": \"Input1D\", \"features\": [\n",
    "                {\"class\": \"RawContextFeature\", \"params\": {\"name\":\"is_open\"}},\n",
    "                {\"class\": \"RawValueFeature\", \"params\": {\"name\":\"open_signal\"}},\n",
    "                {\"class\": \"RawValueFeature\", \"params\": {\"name\":\"close_signal\"}},\n",
    "                {\"class\": \"RawContextFeature\", \"params\": {\"name\":\"open_signal\"}}\n",
    "            ]},\n",
    "    ]\n",
    "    }\n",
    "}\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "core_constructor = Constructor()\n",
    "env_core = core_constructor.get_core(ALIAS, core_config)\n",
    "\n",
    "# train environment\n",
    "env = TradeEnv(env_core, dpf_train, alias=ALIAS, log=True, log_obs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,060\n",
      "Trainable params: 13,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 12:01:27.073433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ACTIVATION = 'relu'\n",
    "def create_q_model(env):\n",
    "    num_actions = env.action_space\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    inp_static = Input(shape=env.observation_space[0])\n",
    "    classif = Dense(64, activation=ACTIVATION)(inp_static)\n",
    "    classif = Dense(64, activation=ACTIVATION)(classif)\n",
    "    classif = Dense(64, activation=ACTIVATION)(classif)\n",
    "    classif = Dense(64, activation=ACTIVATION)(classif)\n",
    "    output = Dense(num_actions, activation='softmax')(classif)\n",
    "\n",
    "    model = Model(inputs=inp_static, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = create_q_model(env)\n",
    "model_target = create_q_model(env)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed_value)\n",
    "\n",
    "core_train = core_constructor.get_core(\"train\", core_config)\n",
    "env = TradeEnv(core_train, dpf_train, alias=ALIAS, log=True, log_obs=True)\n",
    "\n",
    "model = create_q_model(env)\n",
    "model_target = create_q_model(env)\n",
    "agent = DQNAgent(env, model, model_target)\n",
    "\n",
    "agent.epsilon_random_frames = 500\n",
    "agent.epsilon_greedy_frames = 4000\n",
    "agent.max_memory_length     = 4000\n",
    "agent.max_steps_per_episode = 50000\n",
    "agent.gamma = 0.95\n",
    "agent.epsilon_min = 0.01\n",
    "agent.batch_size = 64\n",
    "agent.update_after_actions = 4\n",
    "agent.update_target_network = 250\n",
    "agent.loss_function = tf.keras.losses.Huber() #tf.keras.losses.MeanSquaredError()\n",
    "agent.optimizer = Adam(learning_rate=0.001, clipnorm=0.001)    #Adam(learning_rate=learning_rate) RMSprop(learning_rate=learning_rate) SGD(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "tp = TrainPlot4()\n",
    "core_test = core_constructor.get_core(\"test\", core_config)\n",
    "tm = TrainManager(agent, core_test, dpf_test, tp, alias=ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd3bd3a393840c39f0cd0adc88fb782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'legendgroup': '1',\n",
       "              'line': {'color': '#109618', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dea61004-3e8d-4502-b868-630e8fd5e9b6',\n",
       "              'xaxis': 'x',\n",
       "              'yaxis': 'y'},\n",
       "             {'legendgroup': '1',\n",
       "              'line': {'color': '#FF9900', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Test',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6698cbd6-975e-465f-ab29-3c8a2cf6e552',\n",
       "              'xaxis': 'x',\n",
       "              'yaxis': 'y'},\n",
       "             {'legendgroup': '2',\n",
       "              'line': {'color': '#D62728', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train',\n",
       "              'type': 'scatter',\n",
       "              'uid': '4ba117a1-dcf3-4a2c-8802-05caf87657c9',\n",
       "              'xaxis': 'x2',\n",
       "              'yaxis': 'y3'},\n",
       "             {'legendgroup': '2',\n",
       "              'line': {'color': '#FF9900', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Test',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'bc5f3a7a-17a4-4f2c-babd-a6bd2f74d688',\n",
       "              'xaxis': 'x2',\n",
       "              'yaxis': 'y3'},\n",
       "             {'legendgroup': '3',\n",
       "              'line': {'color': '#1616A7', 'dash': 'dot', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'PosTrades',\n",
       "              'type': 'scatter',\n",
       "              'uid': '1c77366c-8cf0-4201-b5e8-a87d4dc053e8',\n",
       "              'xaxis': 'x3',\n",
       "              'yaxis': 'y5'},\n",
       "             {'legendgroup': '3',\n",
       "              'line': {'color': '#FB0D0D', 'dash': 'dot', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'NegTrades',\n",
       "              'type': 'scatter',\n",
       "              'uid': '75cbc6c5-5a74-40ab-a62f-c21a4ad6a52d',\n",
       "              'xaxis': 'x3',\n",
       "              'yaxis': 'y5'},\n",
       "             {'legendgroup': '3',\n",
       "              'line': {'color': 'rgb(102,102,102)', 'width': 1},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Sparsity',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'dfc604ac-a441-4d85-81cb-1cf28812f5dc',\n",
       "              'xaxis': 'x3',\n",
       "              'yaxis': 'y6'}],\n",
       "    'layout': {'annotations': [{'font': {'size': 16},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'Trade Balance',\n",
       "                                'x': 0.47,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 1.0,\n",
       "                                'yanchor': 'bottom',\n",
       "                                'yref': 'paper'},\n",
       "                               {'font': {'size': 16},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'Penalties',\n",
       "                                'x': 0.47,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 0.6399999999999999,\n",
       "                                'yanchor': 'bottom',\n",
       "                                'yref': 'paper'},\n",
       "                               {'font': {'size': 16},\n",
       "                                'showarrow': False,\n",
       "                                'text': 'Num of trades by profit',\n",
       "                                'x': 0.47,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 0.27999999999999997,\n",
       "                                'yanchor': 'bottom',\n",
       "                                'yref': 'paper'}],\n",
       "               'autosize': False,\n",
       "               'height': 800,\n",
       "               'legend': {'tracegroupgap': 180},\n",
       "               'paper_bgcolor': 'rgba(255,255,255,0)',\n",
       "               'plot_bgcolor': 'rgba(245,245,245,245)',\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y', 'domain': [0.0, 0.94], 'matches': 'x3', 'showticklabels': False},\n",
       "               'xaxis2': {'anchor': 'y3', 'domain': [0.0, 0.94], 'matches': 'x3', 'showticklabels': False},\n",
       "               'xaxis3': {'anchor': 'y5', 'domain': [0.0, 0.94]},\n",
       "               'yaxis': {'anchor': 'x', 'domain': [0.72, 1.0]},\n",
       "               'yaxis2': {'anchor': 'x', 'overlaying': 'y', 'side': 'right'},\n",
       "               'yaxis3': {'anchor': 'x2', 'domain': [0.36, 0.6399999999999999]},\n",
       "               'yaxis4': {'anchor': 'x2', 'overlaying': 'y3', 'side': 'right'},\n",
       "               'yaxis5': {'anchor': 'x3', 'domain': [0.0, 0.27999999999999997]},\n",
       "               'yaxis6': {'anchor': 'x3', 'overlaying': 'y5', 'range': [0, 1], 'showgrid': False, 'side': 'right'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp.init_plot(width=1000, height=800)\n",
    "tp.update_plot(tm.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:24:31 Running reward: -61.00   at episode 3    | frame 250    | eps: 0.94 | Running loss: 0.29375\n",
      "13:24:35 Running reward: -61.60   at episode 6    | frame 500    | eps: 0.88 | Running loss: 0.19809\n",
      "13:24:38 Running reward: -60.00   at episode 8    | frame 750    | eps: 0.81 | Running loss: 0.15256\n",
      "13:24:42 Running reward: -56.60   at episode 11   | frame 1000   | eps: 0.75 | Running loss: 0.11974\n",
      "13:24:45 Running reward: -55.58   at episode 13   | frame 1250   | eps: 0.69 | Running loss: 0.10581\n",
      "13:24:49 Running reward: -53.07   at episode 16   | frame 1500   | eps: 0.63 | Running loss: 0.09204\n",
      "13:24:54 Running reward: -51.76   at episode 18   | frame 1750   | eps: 0.57 | Running loss: 0.08524\n",
      "13:24:58 Running reward: -49.20   at episode 21   | frame 2000   | eps: 0.51 | Running loss: 0.07830\n",
      "13:25:02 Running reward: -47.59   at episode 23   | frame 2250   | eps: 0.44 | Running loss: 0.07407\n",
      "13:25:07 Running reward: -45.92   at episode 26   | frame 2500   | eps: 0.38 | Running loss: 0.06919\n",
      "13:25:12 Running reward: -43.68   at episode 29   | frame 2750   | eps: 0.32 | Running loss: 0.06540\n",
      "13:25:17 Running reward: -42.10   at episode 31   | frame 3000   | eps: 0.26 | Running loss: 0.06313\n",
      "13:25:23 Running reward: -37.47   at episode 34   | frame 3250   | eps: 0.20 | Running loss: 0.03989\n",
      "13:25:28 Running reward: -34.07   at episode 36   | frame 3500   | eps: 0.13 | Running loss: 0.03556\n",
      "13:25:33 Running reward: -29.47   at episode 39   | frame 3750   | eps: 0.07 | Running loss: 0.03558\n",
      "13:25:38 Running reward: -26.77   at episode 41   | frame 4000   | eps: 0.01 | Running loss: 0.03482\n",
      "13:25:44 Running reward: -22.00   at episode 44   | frame 4250   | eps: 0.01 | Running loss: 0.03440\n",
      "13:25:49 Running reward: -19.33   at episode 46   | frame 4500   | eps: 0.01 | Running loss: 0.03414\n",
      "13:25:54 Running reward: -15.33   at episode 49   | frame 4750   | eps: 0.01 | Running loss: 0.03334\n",
      "13:25:57 Running reward: -12.20   at episode 52   | frame 5000   | eps: 0.01 | Running loss: 0.03256\n",
      "13:26:01 Running reward: -9.80    at episode 54   | frame 5250   | eps: 0.01 | Running loss: 0.03225\n",
      "13:26:06 Running reward: -6.97    at episode 57   | frame 5500   | eps: 0.01 | Running loss: 0.03174\n",
      "13:26:11 Running reward: -5.37    at episode 59   | frame 5750   | eps: 0.01 | Running loss: 0.03108\n",
      "13:26:15 Running reward: -3.70    at episode 62   | frame 6000   | eps: 0.01 | Running loss: 0.03006\n",
      "13:26:19 Running reward: -2.93    at episode 64   | frame 6250   | eps: 0.01 | Running loss: 0.02951\n",
      "13:26:22 Running reward: -1.60    at episode 67   | frame 6500   | eps: 0.01 | Running loss: 0.02779\n",
      "13:26:25 Running reward: -1.40    at episode 69   | frame 6750   | eps: 0.01 | Running loss: 0.02691\n",
      "13:26:28 Running reward: -0.93    at episode 72   | frame 7000   | eps: 0.01 | Running loss: 0.02512\n",
      "13:26:31 Running reward: -0.97    at episode 74   | frame 7250   | eps: 0.01 | Running loss: 0.02391\n",
      "13:26:34 Running reward: -1.00    at episode 77   | frame 7500   | eps: 0.01 | Running loss: 0.02230\n",
      "13:26:37 Running reward: -1.07    at episode 80   | frame 7750   | eps: 0.01 | Running loss: 0.02105\n",
      "13:26:40 Running reward: -1.00    at episode 82   | frame 8000   | eps: 0.01 | Running loss: 0.02027\n",
      "13:26:43 Running reward: -1.03    at episode 85   | frame 8250   | eps: 0.01 | Running loss: 0.01858\n",
      "13:26:46 Running reward: -1.20    at episode 87   | frame 8500   | eps: 0.01 | Running loss: 0.01788\n",
      "13:26:50 Running reward: -3.70    at episode 90   | frame 8750   | eps: 0.01 | Running loss: 0.01725\n",
      "13:26:53 Running reward: -3.60    at episode 92   | frame 9000   | eps: 0.01 | Running loss: 0.01655\n",
      "13:26:56 Running reward: -3.87    at episode 95   | frame 9250   | eps: 0.01 | Running loss: 0.01609\n",
      "13:26:59 Running reward: -4.73    at episode 97   | frame 9500   | eps: 0.01 | Running loss: 0.01620\n",
      "13:27:03 Running reward: -4.70    at episode 100  | frame 9750   | eps: 0.01 | Running loss: 0.01595\n",
      "13:27:05 Running reward: -5.80    at episode 103  | frame 10000  | eps: 0.01 | Running loss: 0.01607\n",
      "13:27:09 Running reward: -6.67    at episode 105  | frame 10250  | eps: 0.01 | Running loss: 0.01662\n",
      "13:27:13 Running reward: -7.33    at episode 108  | frame 10500  | eps: 0.01 | Running loss: 0.01751\n",
      "13:27:17 Running reward: -10.37   at episode 110  | frame 10750  | eps: 0.01 | Running loss: 0.01848\n",
      "13:27:21 Running reward: -10.47   at episode 113  | frame 11000  | eps: 0.01 | Running loss: 0.01969\n",
      "13:27:25 Running reward: -11.47   at episode 115  | frame 11250  | eps: 0.01 | Running loss: 0.02060\n",
      "13:27:29 Running reward: -11.23   at episode 118  | frame 11500  | eps: 0.01 | Running loss: 0.02212\n",
      "13:27:32 Running reward: -10.20   at episode 120  | frame 11750  | eps: 0.01 | Running loss: 0.02325\n",
      "13:27:36 Running reward: -10.47   at episode 123  | frame 12000  | eps: 0.01 | Running loss: 0.02517\n",
      "13:27:39 Running reward: -10.13   at episode 125  | frame 12250  | eps: 0.01 | Running loss: 0.02646\n",
      "13:27:43 Running reward: -9.20    at episode 128  | frame 12500  | eps: 0.01 | Running loss: 0.02827\n",
      "13:27:47 Running reward: -9.20    at episode 131  | frame 12750  | eps: 0.01 | Running loss: 0.02954\n",
      "13:27:50 Running reward: -9.97    at episode 133  | frame 13000  | eps: 0.01 | Running loss: 0.03110\n",
      "13:27:54 Running reward: -8.57    at episode 136  | frame 13250  | eps: 0.01 | Running loss: 0.03239\n",
      "13:27:57 Running reward: -8.20    at episode 138  | frame 13500  | eps: 0.01 | Running loss: 0.03308\n",
      "13:28:01 Running reward: -5.97    at episode 141  | frame 13750  | eps: 0.01 | Running loss: 0.03370\n",
      "13:28:05 Running reward: -5.90    at episode 143  | frame 14000  | eps: 0.01 | Running loss: 0.03389\n",
      "13:28:08 Running reward: -4.80    at episode 146  | frame 14250  | eps: 0.01 | Running loss: 0.03420\n",
      "13:28:12 Running reward: -4.77    at episode 148  | frame 14500  | eps: 0.01 | Running loss: 0.03448\n",
      "13:28:16 Running reward: -3.13    at episode 151  | frame 14750  | eps: 0.01 | Running loss: 0.03376\n",
      "13:28:19 Running reward: -2.97    at episode 154  | frame 15000  | eps: 0.01 | Running loss: 0.03280\n",
      "13:28:22 Running reward: -3.00    at episode 156  | frame 15250  | eps: 0.01 | Running loss: 0.03152\n",
      "13:28:26 Running reward: -5.23    at episode 159  | frame 15500  | eps: 0.01 | Running loss: 0.03066\n",
      "13:28:30 Running reward: -5.27    at episode 161  | frame 15750  | eps: 0.01 | Running loss: 0.03032\n",
      "13:28:33 Running reward: -4.43    at episode 164  | frame 16000  | eps: 0.01 | Running loss: 0.02950\n",
      "13:28:37 Running reward: -4.57    at episode 166  | frame 16250  | eps: 0.01 | Running loss: 0.02871\n",
      "13:28:41 Running reward: -5.30    at episode 169  | frame 16500  | eps: 0.01 | Running loss: 0.02849\n",
      "13:28:45 Running reward: -5.37    at episode 171  | frame 16750  | eps: 0.01 | Running loss: 0.02837\n",
      "13:28:48 Running reward: -6.50    at episode 174  | frame 17000  | eps: 0.01 | Running loss: 0.02800\n",
      "13:28:52 Running reward: -7.90    at episode 177  | frame 17250  | eps: 0.01 | Running loss: 0.02764\n",
      "13:28:56 Running reward: -7.77    at episode 179  | frame 17500  | eps: 0.01 | Running loss: 0.02795\n",
      "13:29:00 Running reward: -7.43    at episode 182  | frame 17750  | eps: 0.01 | Running loss: 0.02813\n",
      "13:29:04 Running reward: -7.40    at episode 184  | frame 18000  | eps: 0.01 | Running loss: 0.02866\n",
      "13:29:08 Running reward: -6.77    at episode 187  | frame 18250  | eps: 0.01 | Running loss: 0.02994\n",
      "13:29:11 Running reward: -4.60    at episode 189  | frame 18500  | eps: 0.01 | Running loss: 0.03040\n",
      "13:29:14 Running reward: -3.37    at episode 192  | frame 18750  | eps: 0.01 | Running loss: 0.03138\n",
      "13:29:18 Running reward: -1.93    at episode 194  | frame 19000  | eps: 0.01 | Running loss: 0.03183\n",
      "13:29:22 Running reward: 0.03     at episode 197  | frame 19250  | eps: 0.01 | Running loss: 0.03257\n",
      "13:29:25 Running reward: 1.03     at episode 199  | frame 19500  | eps: 0.01 | Running loss: 0.03258\n",
      "13:29:29 Running reward: 0.63     at episode 202  | frame 19750  | eps: 0.01 | Running loss: 0.03231\n",
      "13:29:33 Running reward: 3.80     at episode 205  | frame 20000  | eps: 0.01 | Running loss: 0.03268\n",
      "13:29:38 Running reward: 4.17     at episode 207  | frame 20250  | eps: 0.01 | Running loss: 0.03269\n",
      "13:29:42 Running reward: 4.70     at episode 210  | frame 20500  | eps: 0.01 | Running loss: 0.03270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:29:46 Running reward: 5.20     at episode 212  | frame 20750  | eps: 0.01 | Running loss: 0.03285\n",
      "13:29:49 Running reward: 6.07     at episode 215  | frame 21000  | eps: 0.01 | Running loss: 0.03262\n",
      "13:29:52 Running reward: 6.30     at episode 217  | frame 21250  | eps: 0.01 | Running loss: 0.03252\n",
      "13:29:56 Running reward: 6.63     at episode 220  | frame 21500  | eps: 0.01 | Running loss: 0.03198\n",
      "13:29:59 Running reward: 6.77     at episode 222  | frame 21750  | eps: 0.01 | Running loss: 0.03151\n",
      "13:30:02 Running reward: 6.70     at episode 225  | frame 22000  | eps: 0.01 | Running loss: 0.03131\n",
      "13:30:06 Running reward: 7.00     at episode 228  | frame 22250  | eps: 0.01 | Running loss: 0.03090\n",
      "13:30:09 Running reward: 6.90     at episode 230  | frame 22500  | eps: 0.01 | Running loss: 0.03086\n",
      "13:30:12 Running reward: 8.57     at episode 233  | frame 22750  | eps: 0.01 | Running loss: 0.03113\n",
      "13:30:16 Running reward: 8.73     at episode 235  | frame 23000  | eps: 0.01 | Running loss: 0.03075\n",
      "13:30:19 Running reward: 8.53     at episode 238  | frame 23250  | eps: 0.01 | Running loss: 0.03069\n",
      "13:30:23 Running reward: 8.53     at episode 240  | frame 23500  | eps: 0.01 | Running loss: 0.03052\n",
      "13:30:27 Running reward: 8.40     at episode 243  | frame 23750  | eps: 0.01 | Running loss: 0.03040\n",
      "13:30:31 Running reward: 8.07     at episode 245  | frame 24000  | eps: 0.01 | Running loss: 0.03036\n",
      "13:30:34 Running reward: 8.30     at episode 248  | frame 24250  | eps: 0.01 | Running loss: 0.02994\n",
      "13:30:37 Running reward: 8.03     at episode 250  | frame 24500  | eps: 0.01 | Running loss: 0.02959\n",
      "13:30:41 Running reward: 8.10     at episode 253  | frame 24750  | eps: 0.01 | Running loss: 0.02904\n",
      "13:30:44 Running reward: 8.10     at episode 256  | frame 25000  | eps: 0.01 | Running loss: 0.02856\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "tm.go(max_frames=25000, test_every=100, snapshot_every=500000, update_plot_every=100, save_since=0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Базовый конфиг: 11к, 8.8к*, 11к*, 9.7k, 12к Общая черта - нестабильность после выхода на оптимальный результат.\n",
    "    - 4 слой 32 нейрона: 19к, 5к, 12к, 7к, 15к Стабильность результатов выше, но бывает что без колбасы, а бывает, что как на 3 слоях.\n",
    "    - 4 слоя по 64 нейрона: 5к, 8к, 17к, 10к,  Небольшая нестабильность в начале\n",
    "        - agent.epsilon_greedy_frames = 8000(было 2к): 28к, 52k, 20k. По ощущениям стало дольше обучаться и расколбас сохраняется\n",
    "            -lr=0.00025 (было 0.0005): 28к\n",
    "        - epsilon_greedy_frames = 20000(было 2к): 36к, 66к, 36к есть нестабильность\n",
    "        \n",
    "        - utn=500: 16к, 21k иногда есть нестабильность.\n",
    "        - utn=250: 14к, 14к, 14k\n",
    "            - 3 слоя по 64: 17k, 20k, 11k\n",
    "        \n",
    "    - 64-32-16-18 | utn=250 | egf=2000: 15k, x Нестабильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cursor': 1,\n",
       " 'state': True,\n",
       " 'observation': '[1.,0.]',\n",
       " 'action': 1,\n",
       " 'reward': 0,\n",
       " 'total_reward': 0,\n",
       " 'balance': 0,\n",
       " 'profit': None,\n",
       " 'lowest_ask': 0,\n",
       " 'highest_bid': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_step_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "dp = env.dp_factory.get_current_step()\n",
    "obs = env.core.get_observation(data_point=dp)\n",
    "\n",
    "agent._sample_transformer(obs)\n",
    "\n",
    "indices = random.sample(range(len(agent.done_history)), agent.batch_size)\n",
    "state_sample = [agent.state_history[i] for i in indices]\n",
    "\n",
    "\n",
    "agent._batch_transformer(state_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "model = create_q_model(env)\n",
    "model_target = create_q_model(env)\n",
    "\n",
    "env.live_train_plot.init_plot(fig_size_x=20, fig_size_y=8, dpi=50, update=1)\n",
    "\n",
    "agent = DQN(env, model, model_target, dqn_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env.live_train_plot.lines[\"TotalReward\"].ax.set_ylim(ymin=-1, ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.train(max_frames=100000, goal_reward=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save('models/model_' + ALIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги\n",
    "\n",
    "Наиболее простая задача из всех.\n",
    "\n",
    "Сеть обучилась эффективному алгоримту - открывает и сразу закрывает сделку, без ожидания. Чем больше количество закрытых сделок, тем выше совокупная награда.\n",
    "\n",
    "При одном слое из 4-х нейронов к концу обучения не выходила на оптимальнsй результат. При увеличении кол-ва нейронов или глубины алгоритм стал сходиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (5.9.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from plotly) (8.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rt_project_env",
   "language": "python",
   "name": "rt_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
